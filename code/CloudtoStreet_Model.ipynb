{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-27T13:45:58.621994Z",
     "iopub.status.busy": "2022-10-27T13:45:58.621628Z",
     "iopub.status.idle": "2022-10-27T13:45:58.772505Z",
     "shell.execute_reply": "2022-10-27T13:45:58.771524Z",
     "shell.execute_reply.started": "2022-10-27T13:45:58.621963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Water-Net: flood extraction network combining Transformer and CNN from SAR\n",
    "# Author: Teng Zhao, Xiaoping Du and Xiangtao Fan.\n",
    "# Version: 1.0\n",
    "# Date:27/11/2022\n",
    "#导入相关库\n",
    "import os\n",
    "import imageio as io\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Input, Conv2D, MaxPooling2D, \\\n",
    "    UpSampling2D, Concatenate, Dense, multiply, Permute, Add, Lambda,BatchNormalization, Activation, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "#超参数设置：\n",
    "dropout_rate    = 0.1   #Swin Transformer 舍弃率\n",
    "w = 0.7  #损失函数权重系数\n",
    "EPOCHS =100  #循环次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义相关模块\n",
    "\n",
    "def cbam_block(cbam_feature, ratio=8):\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "\n",
    "def channel_attention(input_feature, ratio=2):\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    shared_layer_one = Dense(channel // ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2, 3, 1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=1,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          use_bias=False)(concat)\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
    "    )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        windows,\n",
    "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
    "    )\n",
    "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super(DropPath, self).__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if self.drop_prob == 0.0 or not training:\n",
    "            return inputs\n",
    "        else:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            path_mask_shape = (batch_size,) + (1,) * (len(tf.shape(inputs)) - 1)\n",
    "            path_mask = tf.floor(\n",
    "                backend.random_bernoulli(path_mask_shape, p=keep_prob)\n",
    "            )\n",
    "            outputs = (\n",
    "                tf.math.divide(tf.cast(inputs, dtype=tf.float32), keep_prob) * path_mask\n",
    "            )\n",
    "            return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"drop_prob\": self.drop_prob,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        window_size,\n",
    "        num_heads,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        return_attention_scores=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.return_attention_scores = return_attention_scores\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            shape=(\n",
    "                (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1),\n",
    "                self.num_heads,\n",
    "            ),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"relative_position_bias_table\",\n",
    "        )\n",
    "\n",
    "        self.relative_position_index = self.get_relative_position_index(\n",
    "            self.window_size[0], self.window_size[1]\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def get_relative_position_index(self, window_height, window_width):\n",
    "        x_x, y_y = tf.meshgrid(range(window_height), range(window_width))\n",
    "        coords = tf.stack([y_y, x_x], axis=0)\n",
    "        coords_flatten = tf.reshape(coords, [2, -1])\n",
    "\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = tf.transpose(relative_coords, perm=[1, 2, 0])\n",
    "\n",
    "        x_x = (relative_coords[:, :, 0] + window_height - 1) * (2 * window_width - 1)\n",
    "        y_y = relative_coords[:, :, 1] + window_width - 1\n",
    "        relative_coords = tf.stack([x_x, y_y], axis=-1)\n",
    "\n",
    "        return tf.reduce_sum(relative_coords, axis=-1)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        relative_position_bias = tf.gather(\n",
    "            self.relative_position_bias_table,\n",
    "            self.relative_position_index,\n",
    "            axis=0,\n",
    "        )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, [2, 0, 1])\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
    "            )\n",
    "            attn = (\n",
    "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
    "                + mask_float\n",
    "            )\n",
    "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "\n",
    "        if self.return_attention_scores:\n",
    "            return x_qkv, attn\n",
    "        else:\n",
    "            return x_qkv\n",
    "    \n",
    "    \n",
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(SwinTransformer, self).__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim \n",
    "        self.num_patch = num_patch  \n",
    "        self.num_heads = num_heads \n",
    "        self.window_size = window_size  \n",
    "        self.shift_size = shift_size  \n",
    "        self.num_mlp = num_mlp  \n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size=(self.window_size, self.window_size),\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.drop_path = (\n",
    "            DropPath(dropout_rate) if dropout_rate > 0.0 else tf.identity\n",
    "        )\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
    "            )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
    "                mask_windows, axis=2\n",
    "            )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        _, num_patches_before, channels = x.shape\n",
    "        height,width = self.num_patch\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
    "        )\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
    "        )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "        )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = tf.cast(x_skip, dtype=tf.float32) + tf.cast(x, dtype=tf.float32)\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = tf.cast(x_skip, dtype=tf.float32) + tf.cast(x, dtype=tf.float32)\n",
    "        return x\n",
    "\n",
    "#针对（512,512）输入尺寸下影像，设置相应的swin Transformer模块参数\n",
    "swin_sequences_128 = keras.Sequential(name=\"swin_blocks_128\")\n",
    "swin_sequences_128.add(\n",
    "                SwinTransformer(\n",
    "                    dim=32,\n",
    "                    num_patch=(128, 128),\n",
    "                    num_heads=4,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=128,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_128.add(\n",
    "                SwinTransformer(\n",
    "                    dim=32,\n",
    "                    num_patch=(128, 128),\n",
    "                    num_heads=4,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=128,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_64 = keras.Sequential(name=\"swin_blocks_64\")\n",
    "swin_sequences_64.add(\n",
    "                SwinTransformer(\n",
    "                    dim=64,\n",
    "                    num_patch=(64, 64),\n",
    "                    num_heads=8,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=256,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_64.add(\n",
    "                SwinTransformer(\n",
    "                    dim=64,\n",
    "                    num_patch=(64, 64),\n",
    "                    num_heads=8,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=256,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_32 = keras.Sequential(name=\"swin_blocks_32\")\n",
    "swin_sequences_32.add(\n",
    "                SwinTransformer(\n",
    "                    dim=96,\n",
    "                    num_patch=(32, 32),\n",
    "                    num_heads=12,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=384,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_32.add(\n",
    "                SwinTransformer(\n",
    "                    dim=96,\n",
    "                    num_patch=(32, 32),\n",
    "                    num_heads=12,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=384,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_16 = keras.Sequential(name=\"swin_blocks_16\")\n",
    "swin_sequences_16.add(\n",
    "                SwinTransformer(\n",
    "                    dim=128,\n",
    "                    num_patch=(16, 16),\n",
    "                    num_heads=16,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=512,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_16.add(\n",
    "                SwinTransformer(\n",
    "                    dim=128,\n",
    "                    num_patch=(16, 16),\n",
    "                    num_heads=16,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=512,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "transformer_block = [swin_sequences_128,swin_sequences_64,swin_sequences_32,swin_sequences_16]\n",
    "#定义损失函数\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_pred = tf.where(y_pred >= 0.5, 1., 0.)\n",
    "    intersection = K.sum(y_true * y_pred, axis=-1)  ##y_true与y_pred都是矩阵！（Unet）\n",
    "    union = K.sum(y_true, axis=-1) + K.sum(y_pred, axis=-1)\n",
    "    return 1 - K.mean((2. * intersection + smooth) / (union + smooth))\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return w * tf.keras.losses.binary_crossentropy(in_gt, in_pred) + (1 - w) * dice_coef(in_gt, in_pred)\n",
    "#定义卷积块\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer=\"he_normal\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "#     x= Dropout(0.1)(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "#     x= Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "# Defining the Transpose Convolution Block\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "#     channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "#     channel = input.shape[channel_axis]\n",
    "    x = tf.keras.layers.UpSampling2D(2, interpolation=\"bilinear\")(input)\n",
    "#     x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "    return x\n",
    "def fusion_module(x, n_feature, stride_size=(1, 1), shortcut=False, **kwargs):\n",
    "    out = tf.keras.layers.Conv2D(n_feature, 3, strides=stride_size, padding=\"same\", use_bias=False,\n",
    "                                 kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(x)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(out)\n",
    "    out = tfa.activations.mish(out)\n",
    "\n",
    "    out = tf.keras.layers.Conv2D(n_feature, 3, padding=\"same\", use_bias=False, kernel_initializer=\"he_normal\",\n",
    "                                 bias_initializer=\"zeros\")(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(out)\n",
    "    out = tf.keras.layers.Add()([out, x])\n",
    "    out = tfa.activations.mish(out)\n",
    "    \n",
    "    return out\n",
    "#对应多尺度交互模块中的两个环节代码：\n",
    "def MSA_Module_1(x, n_branch=4, shortcut=False, **kwargs):\n",
    "    \n",
    "    #不同尺度交互\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    n_feature = [tf.keras.backend.int_shape(_x)[-1] for _x in x]\n",
    "    out = list(x)\n",
    "    outs = []\n",
    "    for index, _n_feature in enumerate(n_feature):\n",
    "        _out = []\n",
    "        for seq, o in enumerate(out):\n",
    "            if seq < index:\n",
    "                for k in range(index - seq):\n",
    "                    o = tf.keras.layers.Conv2D(_n_feature, 3, strides=2, padding=\"same\", use_bias=False,\n",
    "                                               kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(o)\n",
    "                    o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                    if k != (index - seq - 1):\n",
    "                        o = tfa.activations.mish(o)\n",
    "            elif seq == index:\n",
    "                pass\n",
    "            else:  # index < seq\n",
    "                o = tf.keras.layers.Conv2D(_n_feature, 1, use_bias=False, kernel_initializer=\"he_normal\",\n",
    "                                           bias_initializer=\"zeros\")(o)\n",
    "                o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                upsample_size = [2 ** (seq - index)] * 2\n",
    "                o = tf.keras.layers.UpSampling2D(upsample_size, interpolation=\"bilinear\")(o)\n",
    "            _out.append(o)\n",
    "        _out = tf.keras.layers.Add()(_out)\n",
    "        _out = tfa.activations.mish(_out)\n",
    "        outs.append(_out)\n",
    "    #全局维度建模\n",
    "    for i in range(len(outs)):\n",
    "            transform_out = outs[i]\n",
    "            patch_dim = transform_out.shape[-1]\n",
    "            patch_num = transform_out.shape[1]\n",
    "            print(patch_dim,patch_num)\n",
    "            transform_out = tf.reshape(transform_out, (-1, patch_num * patch_num, patch_dim))\n",
    "            transform_out = transformer_block[i](transform_out)\n",
    "            transform_out = tf.reshape(transform_out, (-1, patch_num,patch_num, patch_dim))\n",
    "            outs[i] = transform_out\n",
    "    return outs\n",
    "\n",
    "def MSA_Module_2(x, n_branch=4, shortcut=False, **kwargs):\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    n_feature = [tf.keras.backend.int_shape(_x)[-1] for _x in x]\n",
    "    out = list(x)\n",
    "    outs = []\n",
    "    for index, _n_feature in enumerate(n_feature):\n",
    "        _out = []\n",
    "        for seq, o in enumerate(out):\n",
    "            if seq < index:\n",
    "                for k in range(index - seq):\n",
    "                    o = tf.keras.layers.Conv2D(_n_feature, 3, strides=2, padding=\"same\", use_bias=False,\n",
    "                                               kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(o)\n",
    "                    o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                    if k != (index - seq - 1):\n",
    "                        o = tfa.activations.mish(o)\n",
    "            elif seq == index:\n",
    "                pass\n",
    "            else:  # index < seq\n",
    "                o = tf.keras.layers.Conv2D(_n_feature, 1, use_bias=False, kernel_initializer=\"he_normal\",\n",
    "                                           bias_initializer=\"zeros\")(o)\n",
    "                o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                upsample_size = [2 ** (seq - index)] * 2\n",
    "                o = tf.keras.layers.UpSampling2D(upsample_size, interpolation=\"bilinear\")(o)\n",
    "            _out.append(o)\n",
    "        _out = tf.keras.layers.Add()(_out)\n",
    "        _out = tfa.activations.mish(_out)\n",
    "        outs.append(_out)\n",
    "    for _ in range(n_branch):\n",
    "        for index, _n_feature in enumerate(n_feature):\n",
    "            outs[index] = fusion_module(outs[index], _n_feature, shortcut=shortcut, **kwargs)\n",
    "    return outs\n",
    "def MSAM(x,n_channel=[32, 64, 96, 128],**kwargs):\n",
    "    x = list(x)\n",
    "    shape = tf.keras.backend.int_shape(x[0])[-3:-1]\n",
    "    #1*1降维\n",
    "    for index in range(len(x)):\n",
    "        o = tf.keras.layers.Conv2D(n_channel[index], 1, padding=\"same\", use_bias=False,\n",
    "                                   kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(x[index])\n",
    "        o = BatchNormalization()(o)\n",
    "        o = tfa.activations.mish(o)\n",
    "        x[index] = o\n",
    "    #两个多尺度交互\n",
    "    out = MSA_Module_1(x, n_branch=4, shortcut=False, **kwargs)\n",
    "    out = MSA_Module_2(out, n_branch=4, shortcut=False, **kwargs)\n",
    "    #上采样至统一尺寸输出\n",
    "    for index in range(1, len(out)):\n",
    "            upsample_size = np.divide(tf.keras.backend.int_shape(out[0])[-3:-1],\n",
    "                                      tf.keras.backend.int_shape(out[index])[-3:-1]).astype(np.int32)\n",
    "            out[index] = tf.keras.layers.UpSampling2D(upsample_size, interpolation=\"bilinear\")(out[index])\n",
    "        out = tf.keras.layers.Concatenate(axis=-1)(out)\n",
    "        out = Conv2D(128, 1, padding=\"same\", kernel_initializer=\"he_normal\")(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = tfa.activations.mish(out)\n",
    "        out = cbam_block(out)\n",
    "        \n",
    "    return out\n",
    "# Building the Water-Net\n",
    "def Water_Net(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input_image')\n",
    "\n",
    "    \"\"\"EfficientNetB0 Model \"\"\"\n",
    "    effNetB4 = tf.keras.applications.EfficientNetB0(input_tensor=inputs, include_top=False)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = effNetB4.get_layer(\"input_image\").output  ## (512 x 512)\n",
    "    s1 = conv_block(s1,32)\n",
    "    s2 = effNetB4.get_layer(\"block1a_activation\").output  ## (256 x 256)\n",
    "    s3 = effNetB4.get_layer(\"block2a_activation\").output  ## (128 x 128)\n",
    "    s4 = effNetB4.get_layer(\"block3a_activation\").output  ## (64 x 64)\n",
    "    s5 = effNetB4.get_layer(\"block4a_activation\").output  ## (32 x 32)\n",
    "    b1 = effNetB4.get_layer(\"block7a_activation\").output\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    input_layers = [s3,s4,s5,b1]\n",
    "    out = MSAM(input_layers)\n",
    "    d4 = decoder_block(out, s2, 64)  ## (256 x 256)\n",
    "    d5 = decoder_block(d4, s1, 32)  ## (512 x 512)\n",
    "    \n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\",name =\"outputs\")(d5)\n",
    "    model = Model(inputs, outputs, name=\"EfficientNetB4_U-Net\")\n",
    "    return model\n",
    "\n",
    "#绘制损失函数等指标曲线\n",
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'auc', 'precision', 'recall']\n",
    "    plt.figure()\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric\n",
    "        plt.subplot(2, 2, n + 1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=\"green\", label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_' + metric],\n",
    "                 color=\"red\", linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8, 1])\n",
    "        else:\n",
    "            plt.ylim([0, 1])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#定义meanIOU指标函数\n",
    "def get_iou_vector(A, B):\n",
    "    intersection = 0\n",
    "    union =0\n",
    "    B = np.where(B >= 0.5, 1., 0.)\n",
    "    intersection =np.logical_and(A, B).sum()\n",
    "    union =np.logical_or(A, B).sum()\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.numpy_function(get_iou_vector, [label, pred], tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-27T13:43:21.050270Z",
     "iopub.status.idle": "2022-10-27T13:43:21.050795Z",
     "shell.execute_reply": "2022-10-27T13:43:21.050562Z",
     "shell.execute_reply.started": "2022-10-27T13:43:21.050513Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义输出路径\n",
    "mkdir -p ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-27T13:46:03.444122Z",
     "iopub.status.busy": "2022-10-27T13:46:03.443739Z",
     "iopub.status.idle": "2022-10-27T13:47:00.188729Z",
     "shell.execute_reply": "2022-10-27T13:47:00.186438Z",
     "shell.execute_reply.started": "2022-10-27T13:46:03.444089Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_paths = r\"../input/avert-data/process_data/image/\"\n",
    "train_mask_paths = r\"../input/avert-data/process_data/label/\"\n",
    "test_image_paths =  r\"../input/avert-data/process_data/test_image/\"\n",
    "test_mask_paths = r\"../input/avert-data/process_data/test_label/\"\n",
    "val_image_paths =  r\"../input/avert-data/process_data/val_image/\"\n",
    "val_mask_paths = r\"../input/avert-data/process_data/val_label/\"\n",
    "train_filenames = os.listdir(train_image_paths)\n",
    "test_filenames = os.listdir(test_image_paths)\n",
    "val_filenames = os.listdir(val_image_paths)\n",
    "num_image = len(train_filenames)\n",
    "test_num = len(test_filenames)\n",
    "print(num_image,test_num)\n",
    "\n",
    "def load_img_and_mask(image_path,mask_path,filename):\n",
    "\n",
    "    image = tf.io.read_file(image_path +filename)         #read file into buffer\n",
    "    image = tf.image.decode_png(image, channels=3)             #decode jpeg into tensor\n",
    "    mask_filename = (mask_path +filename)                      #create full filename for masks\n",
    "    mask = tf.io.read_file(mask_filename)                       #read masks\n",
    "    mask = tf.image.decode_png(mask, channels=1)              #decode mask into tensor\n",
    "#     mask = tf.stack([mask,mask],axis=0)\n",
    "    return (image, mask)                                        #return image and mask as a tuple\n",
    "\n",
    "def scale_values(image, mask, mask_split_threshold=128):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "#     image = tf.math.divide(image, 255.0)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    mask = tf.where(mask>128, 1., 0.)\n",
    "    return (image, mask)\n",
    "\n",
    "\n",
    "print(\"加载及处理数据中——————————\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_filenames)\n",
    "test_dataset =  tf.data.Dataset.from_tensor_slices(test_filenames)\n",
    "val_dataset =  tf.data.Dataset.from_tensor_slices(val_filenames)\n",
    "dataset = dataset.map(lambda x: load_img_and_mask(train_image_paths,\n",
    "                                                  train_mask_paths,\n",
    "                                                   filename=x))\n",
    "test_dataset = test_dataset.map(lambda x: load_img_and_mask(test_image_paths,\n",
    "                                                  test_mask_paths,\n",
    "                                                   filename=x))\n",
    "val_dataset = val_dataset.map(lambda x: load_img_and_mask(val_image_paths,\n",
    "                                                  val_mask_paths,\n",
    "                                                   filename=x))\n",
    "dataset = dataset.map(scale_values)\n",
    "test_dataset = test_dataset.map(scale_values)\n",
    "val_dataset = val_dataset.map(scale_values)\n",
    "train_dataset = dataset.batch(8)\n",
    "val_dataset = val_dataset.batch(8)\n",
    "test_dataset = test_dataset.batch(8)\n",
    "\n",
    "print(f'Original Set: {dataset}')\n",
    "print(f'Training Set: {train_dataset}')\n",
    "print(f'Validation Set: {val_dataset}')\n",
    "print(f'Testing Set: {test_dataset}')\n",
    "METRICS = [\n",
    "    my_iou_metric,\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR'),  # precision-recall curve\n",
    "\n",
    "]\n",
    "checkpoint = ModelCheckpoint(filepath='./model_best_cbam_tenth_2.h5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss',mode='min', patience=10)\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "callbacks = [checkpoint,\n",
    "             early_stopping,\n",
    "            tqdm_callback]\n",
    "model = Water_Net((512, 512, 3))\n",
    "lr_decayed_fn = (\n",
    "  tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "     3e-4,10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decayed_fn)\n",
    "model.compile(optimizer=optimizer, loss=dice_p_bce, metrics = METRICS)\n",
    "history = model.fit(train_dataset ,validation_data=val_dataset,epochs=EPOCHS, callbacks=callbacks,verbose = 2)\n",
    "plot_metrics(history)\n",
    "# 验证阶段\n",
    "model.load_weights('./model_best_cbam_tenth_2.h5')\n",
    "meanIoU = tf.keras.metrics.MeanIoU(num_classes=2)  # define meanIoU\n",
    "meanRecall = tf.keras.metrics.Recall()\n",
    "meanPrecision = tf.keras.metrics.Precision()\n",
    "meanIoU.reset_states()  ##清除之前的计算结果，相当于复位重新开始计算\n",
    "meanRecall.reset_states()  ##清除之前的计算结果，相当于复位重新开始计算\n",
    "meanPrecision.reset_states()  ##清除之前的计算结果，相当于复位重新开始计算\n",
    "k = 0\n",
    "intersection = 0\n",
    "union = 0\n",
    "q = 0\n",
    "now1 = datetime.now()#统计程序开始的时间\n",
    "for ele in test_dataset:  \n",
    "    image, y_true = ele   \n",
    "    prediction = model.predict(image)# make model prediction based on image\n",
    "    prediction = np.where(prediction >= 0.5, 1., 0.)\n",
    "    \n",
    "    for i in range(len(prediction[:,0,0])):\n",
    "        prediction_1 = np.where(prediction > 0.5,255, 0)\n",
    "        y_true_1 = tf.where(y_true >=0.5,255, 0)\n",
    "        test = cv2.merge([image[i][:,:,0].numpy(),image[i][:,:,0].numpy(),image[i][:,:,1].numpy()])\n",
    "        cv2.imwrite(\"./data/%d_image.png\" % q,test) \n",
    "        cv2.imwrite(\"./data/%d_true.png\" % q,y_true_1[i].numpy())\n",
    "        cv2.imwrite(\"./data/%d_prediction.png\" % q,prediction_1[i])\n",
    "        q = q+1\n",
    "    intersection += np.logical_and(y_true, prediction).sum()\n",
    "    union += np.logical_or(y_true, prediction).sum()\n",
    "    meanIoU.update_state(y_true, prediction)  # update the state of the meanIoU metric\n",
    "    meanRecall.update_state(y_true, prediction)\n",
    "    meanPrecision.update_state(y_true, prediction)\n",
    "    print(\"第{}个影像结束：\".format(k))\n",
    "    k = k + 1\n",
    "now2 = datetime.now()#统计程序结束的时间\n",
    "print(now2-now1)#得到程序运行的总时间\n",
    "print(\"meanIOU:\", intersection / union)\n",
    "IoU_result = meanIoU.result().numpy()  # select the Mean IoU score\n",
    "Recall_result = meanRecall.result().numpy()  # select the Mean IoU score\n",
    "Precision_result = meanPrecision.result().numpy()  # select the Mean IoU score\n",
    "print(f'Mean IoU: {IoU_result}')  # print result\n",
    "print(f'Mean Recall: {Recall_result}')  # print result\n",
    "print(f'Mean Precision: {Precision_result}')  # print result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}