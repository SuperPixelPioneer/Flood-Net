{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water-Net: flood extraction network combining Transformer and CNN from SAR\n",
    "# Author: Teng Zhao, Xiaoping Du and Xiangtao Fan.\n",
    "# Version: 1.0\n",
    "# Date:27/11/2022\n",
    "#导入相关库\n",
    "import os\n",
    "import imageio as io\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Input, Conv2D, MaxPooling2D, \\\n",
    "    UpSampling2D, Concatenate, Dense, multiply, Permute, Add, Lambda,BatchNormalization, Activation, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "#超参数设置：\n",
    "dropout_rate    = 0.1   #Swin Transformer 舍弃率\n",
    "w = 0.7  #损失函数权重系数\n",
    "EPOCHS =100  #循环次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####定义模型\n",
    "def cbam_block(cbam_feature, ratio=8):\n",
    "    cbam_feature = channel_attention(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "\n",
    "def channel_attention(input_feature, ratio=2):\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    channel = input_feature.shape[channel_axis]\n",
    "\n",
    "    shared_layer_one = Dense(channel // ratio,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "    shared_layer_two = Dense(channel,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             use_bias=True,\n",
    "                             bias_initializer='zeros')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    assert avg_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel // ratio)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    assert max_pool.shape[1:] == (1, 1, channel)\n",
    "\n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "def spatial_attention(input_feature):\n",
    "    kernel_size = 7\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        channel = input_feature.shape[1]\n",
    "        cbam_feature = Permute((2, 3, 1))(input_feature)\n",
    "    else:\n",
    "        channel = input_feature.shape[-1]\n",
    "        cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert avg_pool.shape[-1] == 1\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    assert max_pool.shape[-1] == 1\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "    assert concat.shape[-1] == 2\n",
    "    cbam_feature = Conv2D(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=1,\n",
    "                          padding='same',\n",
    "                          activation='sigmoid',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          use_bias=False)(concat)\n",
    "    assert cbam_feature.shape[-1] == 1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\n",
    "    return multiply([input_feature, cbam_feature])\n",
    "\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
    "    )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        windows,\n",
    "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
    "    )\n",
    "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super(DropPath, self).__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if self.drop_prob == 0.0 or not training:\n",
    "            return inputs\n",
    "        else:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            path_mask_shape = (batch_size,) + (1,) * (len(tf.shape(inputs)) - 1)\n",
    "            path_mask = tf.floor(\n",
    "                backend.random_bernoulli(path_mask_shape, p=keep_prob)\n",
    "            )\n",
    "            outputs = (\n",
    "                tf.math.divide(tf.cast(inputs, dtype=tf.float32), keep_prob) * path_mask\n",
    "            )\n",
    "            return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"drop_prob\": self.drop_prob,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        window_size,\n",
    "        num_heads,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        return_attention_scores=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.return_attention_scores = return_attention_scores\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            shape=(\n",
    "                (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1),\n",
    "                self.num_heads,\n",
    "            ),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"relative_position_bias_table\",\n",
    "        )\n",
    "\n",
    "        self.relative_position_index = self.get_relative_position_index(\n",
    "            self.window_size[0], self.window_size[1]\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def get_relative_position_index(self, window_height, window_width):\n",
    "        x_x, y_y = tf.meshgrid(range(window_height), range(window_width))\n",
    "        coords = tf.stack([y_y, x_x], axis=0)\n",
    "        coords_flatten = tf.reshape(coords, [2, -1])\n",
    "\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = tf.transpose(relative_coords, perm=[1, 2, 0])\n",
    "\n",
    "        x_x = (relative_coords[:, :, 0] + window_height - 1) * (2 * window_width - 1)\n",
    "        y_y = relative_coords[:, :, 1] + window_width - 1\n",
    "        relative_coords = tf.stack([x_x, y_y], axis=-1)\n",
    "\n",
    "        return tf.reduce_sum(relative_coords, axis=-1)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        relative_position_bias = tf.gather(\n",
    "            self.relative_position_bias_table,\n",
    "            self.relative_position_index,\n",
    "            axis=0,\n",
    "        )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, [2, 0, 1])\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
    "            )\n",
    "            attn = (\n",
    "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
    "                + mask_float\n",
    "            )\n",
    "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "\n",
    "        if self.return_attention_scores:\n",
    "            return x_qkv, attn\n",
    "        else:\n",
    "            return x_qkv\n",
    "    \n",
    "    \n",
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(SwinTransformer, self).__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim \n",
    "        self.num_patch = num_patch  \n",
    "        self.num_heads = num_heads \n",
    "        self.window_size = window_size  \n",
    "        self.shift_size = shift_size  \n",
    "        self.num_mlp = num_mlp  \n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size=(self.window_size, self.window_size),\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.drop_path = (\n",
    "            DropPath(dropout_rate) if dropout_rate > 0.0 else tf.identity\n",
    "        )\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
    "            )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
    "                mask_windows, axis=2\n",
    "            )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        _, num_patches_before, channels = x.shape\n",
    "        height,width = self.num_patch\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
    "        )\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
    "        )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "        )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = tf.cast(x_skip, dtype=tf.float32) + tf.cast(x, dtype=tf.float32)\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = tf.cast(x_skip, dtype=tf.float32) + tf.cast(x, dtype=tf.float32)\n",
    "        return x\n",
    "\n",
    "#针对（512,512）输入尺寸下影像，设置相应的swin Transformer模块参数\n",
    "swin_sequences_128 = keras.Sequential(name=\"swin_blocks_128\")\n",
    "swin_sequences_128.add(\n",
    "                SwinTransformer(\n",
    "                    dim=32,\n",
    "                    num_patch=(128, 128),\n",
    "                    num_heads=4,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=128,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_128.add(\n",
    "                SwinTransformer(\n",
    "                    dim=32,\n",
    "                    num_patch=(128, 128),\n",
    "                    num_heads=4,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=128,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_64 = keras.Sequential(name=\"swin_blocks_64\")\n",
    "swin_sequences_64.add(\n",
    "                SwinTransformer(\n",
    "                    dim=64,\n",
    "                    num_patch=(64, 64),\n",
    "                    num_heads=8,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=256,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_64.add(\n",
    "                SwinTransformer(\n",
    "                    dim=64,\n",
    "                    num_patch=(64, 64),\n",
    "                    num_heads=8,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=256,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_32 = keras.Sequential(name=\"swin_blocks_32\")\n",
    "swin_sequences_32.add(\n",
    "                SwinTransformer(\n",
    "                    dim=96,\n",
    "                    num_patch=(32, 32),\n",
    "                    num_heads=12,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=384,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_32.add(\n",
    "                SwinTransformer(\n",
    "                    dim=96,\n",
    "                    num_patch=(32, 32),\n",
    "                    num_heads=12,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=384,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_16 = keras.Sequential(name=\"swin_blocks_16\")\n",
    "swin_sequences_16.add(\n",
    "                SwinTransformer(\n",
    "                    dim=128,\n",
    "                    num_patch=(16, 16),\n",
    "                    num_heads=16,\n",
    "                    window_size=8,\n",
    "                    shift_size=0,\n",
    "                    num_mlp=512,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "swin_sequences_16.add(\n",
    "                SwinTransformer(\n",
    "                    dim=128,\n",
    "                    num_patch=(16, 16),\n",
    "                    num_heads=16,\n",
    "                    window_size=8,\n",
    "                    shift_size=4,\n",
    "                    num_mlp=512,\n",
    "                    qkv_bias=False,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "            )\n",
    "transformer_block = [swin_sequences_128,swin_sequences_64,swin_sequences_32,swin_sequences_16]\n",
    "#定义卷积块\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer=\"he_normal\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "#     x= Dropout(0.1)(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "#     x= Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "# Defining the Transpose Convolution Block\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "#     channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "#     channel = input.shape[channel_axis]\n",
    "    x = tf.keras.layers.UpSampling2D(2, interpolation=\"bilinear\")(input)\n",
    "#     x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = tfa.activations.mish(x)\n",
    "    return x\n",
    "def fusion_module(x, n_feature, stride_size=(1, 1), shortcut=False, **kwargs):\n",
    "    out = tf.keras.layers.Conv2D(n_feature, 3, strides=stride_size, padding=\"same\", use_bias=False,\n",
    "                                 kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(x)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(out)\n",
    "    out = tfa.activations.mish(out)\n",
    "\n",
    "    out = tf.keras.layers.Conv2D(n_feature, 3, padding=\"same\", use_bias=False, kernel_initializer=\"he_normal\",\n",
    "                                 bias_initializer=\"zeros\")(out)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(out)\n",
    "    out = tf.keras.layers.Add()([out, x])\n",
    "    out = tfa.activations.mish(out)\n",
    "    \n",
    "    return out\n",
    "#对应多尺度交互模块中的两个环节代码：\n",
    "def MSA_Module_1(x, n_branch=4, shortcut=False, **kwargs):\n",
    "    \n",
    "    #不同尺度交互\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    n_feature = [tf.keras.backend.int_shape(_x)[-1] for _x in x]\n",
    "    out = list(x)\n",
    "    outs = []\n",
    "    for index, _n_feature in enumerate(n_feature):\n",
    "        _out = []\n",
    "        for seq, o in enumerate(out):\n",
    "            if seq < index:\n",
    "                for k in range(index - seq):\n",
    "                    o = tf.keras.layers.Conv2D(_n_feature, 3, strides=2, padding=\"same\", use_bias=False,\n",
    "                                               kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(o)\n",
    "                    o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                    if k != (index - seq - 1):\n",
    "                        o = tfa.activations.mish(o)\n",
    "            elif seq == index:\n",
    "                pass\n",
    "            else:  # index < seq\n",
    "                o = tf.keras.layers.Conv2D(_n_feature, 1, use_bias=False, kernel_initializer=\"he_normal\",\n",
    "                                           bias_initializer=\"zeros\")(o)\n",
    "                o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                upsample_size = [2 ** (seq - index)] * 2\n",
    "                o = tf.keras.layers.UpSampling2D(upsample_size, interpolation=\"bilinear\")(o)\n",
    "            _out.append(o)\n",
    "        _out = tf.keras.layers.Add()(_out)\n",
    "        _out = tfa.activations.mish(_out)\n",
    "        outs.append(_out)\n",
    "    #全局维度建模\n",
    "    for i in range(len(outs)):\n",
    "            transform_out = outs[i]\n",
    "            patch_dim = transform_out.shape[-1]\n",
    "            patch_num = transform_out.shape[1]\n",
    "            print(patch_dim,patch_num)\n",
    "            transform_out = tf.reshape(transform_out, (-1, patch_num * patch_num, patch_dim))\n",
    "            transform_out = transformer_block[i](transform_out)\n",
    "            transform_out = tf.reshape(transform_out, (-1, patch_num,patch_num, patch_dim))\n",
    "            outs[i] = transform_out\n",
    "    return outs\n",
    "\n",
    "def MSA_Module_2(x, n_branch=4, shortcut=False, **kwargs):\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    n_feature = [tf.keras.backend.int_shape(_x)[-1] for _x in x]\n",
    "    out = list(x)\n",
    "    outs = []\n",
    "    for index, _n_feature in enumerate(n_feature):\n",
    "        _out = []\n",
    "        for seq, o in enumerate(out):\n",
    "            if seq < index:\n",
    "                for k in range(index - seq):\n",
    "                    o = tf.keras.layers.Conv2D(_n_feature, 3, strides=2, padding=\"same\", use_bias=False,\n",
    "                                               kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(o)\n",
    "                    o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                    if k != (index - seq - 1):\n",
    "                        o = tfa.activations.mish(o)\n",
    "            elif seq == index:\n",
    "                pass\n",
    "            else:  # index < seq\n",
    "                o = tf.keras.layers.Conv2D(_n_feature, 1, use_bias=False, kernel_initializer=\"he_normal\",\n",
    "                                           bias_initializer=\"zeros\")(o)\n",
    "                o = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.9, epsilon=1e-5)(o)\n",
    "                upsample_size = [2 ** (seq - index)] * 2\n",
    "                o = tf.keras.layers.UpSampling2D(upsample_size, interpolation=\"bilinear\")(o)\n",
    "            _out.append(o)\n",
    "        _out = tf.keras.layers.Add()(_out)\n",
    "        _out = tfa.activations.mish(_out)\n",
    "        outs.append(_out)\n",
    "    for _ in range(n_branch):\n",
    "        for index, _n_feature in enumerate(n_feature):\n",
    "            outs[index] = fusion_module(outs[index], _n_feature, shortcut=shortcut, **kwargs)\n",
    "    return outs\n",
    "def MSAM(x,n_channel=[32, 64, 96, 128],**kwargs):\n",
    "    x = list(x)\n",
    "    shape = tf.keras.backend.int_shape(x[0])[-3:-1]\n",
    "    #1*1降维\n",
    "    for index in range(len(x)):\n",
    "        o = tf.keras.layers.Conv2D(n_channel[index], 1, padding=\"same\", use_bias=False,\n",
    "                                   kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(x[index])\n",
    "        o = BatchNormalization()(o)\n",
    "        o = tfa.activations.mish(o)\n",
    "        x[index] = o\n",
    "    #两个多尺度交互\n",
    "    out = MSA_Module_1(x, n_branch=4, shortcut=False, **kwargs)\n",
    "    out = MSA_Module_2(out, n_branch=4, shortcut=False, **kwargs)\n",
    "    #上采样至统一尺寸输出\n",
    "    for index in range(1, len(out)):\n",
    "            upsample_size = np.divide(tf.keras.backend.int_shape(out[0])[-3:-1],\n",
    "                                      tf.keras.backend.int_shape(out[index])[-3:-1]).astype(np.int32)\n",
    "            out[index] = tf.keras.layers.UpSampling2D(upsample_size, interpolation=\"bilinear\")(out[index])\n",
    "        out = tf.keras.layers.Concatenate(axis=-1)(out)\n",
    "        out = Conv2D(128, 1, padding=\"same\", kernel_initializer=\"he_normal\")(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = tfa.activations.mish(out)\n",
    "        out = cbam_block(out)\n",
    "        \n",
    "    return out\n",
    "# Building the Water-Net\n",
    "def Water_Net(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input_image')\n",
    "\n",
    "    \"\"\"EfficientNetB0 Model \"\"\"\n",
    "    effNetB4 = tf.keras.applications.EfficientNetB0(input_tensor=inputs, include_top=False)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = effNetB4.get_layer(\"input_image\").output  ## (512 x 512)\n",
    "    s1 = conv_block(s1,32)\n",
    "    s2 = effNetB4.get_layer(\"block1a_activation\").output  ## (256 x 256)\n",
    "    s3 = effNetB4.get_layer(\"block2a_activation\").output  ## (128 x 128)\n",
    "    s4 = effNetB4.get_layer(\"block3a_activation\").output  ## (64 x 64)\n",
    "    s5 = effNetB4.get_layer(\"block4a_activation\").output  ## (32 x 32)\n",
    "    b1 = effNetB4.get_layer(\"block7a_activation\").output\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    input_layers = [s3,s4,s5,b1]\n",
    "    out = MSAM(input_layers)\n",
    "    d4 = decoder_block(out, s2, 64)  ## (256 x 256)\n",
    "    d5 = decoder_block(d4, s1, 32)  ## (512 x 512)\n",
    "    \n",
    "    \"\"\" Output \"\"\"\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\",name =\"outputs\")(d5)\n",
    "    model = Model(inputs, outputs, name=\"EfficientNetB4_U-Net\")\n",
    "    return model\n",
    "model = Water_Net((512, 512, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载权重\n",
    "model.load_weights('/kaggle/input/07810/CloudtoStreet_Model_Parameter.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载预处理后SAR影像：：\n",
    "import gdal\n",
    "import cv2\n",
    "class GRID:\n",
    "    # 读图像文件\n",
    "    def read_img(self, filename):\n",
    "        dataset = gdal.Open(filename)  # 打开文件\n",
    "\n",
    "        im_width = dataset.RasterXSize  # 栅格矩阵的列数\n",
    "        im_height = dataset.RasterYSize  # 栅格矩阵的行数\n",
    "\n",
    "        im_geotrans = dataset.GetGeoTransform()  # 仿射矩阵\n",
    "        im_proj = dataset.GetProjection()  # 地图投影信息\n",
    "        im_data = dataset.ReadAsArray(0, 0, im_width, im_height)  # 将数据写成数组，对应栅格矩阵\n",
    "        del dataset\n",
    "\n",
    "        return im_width,im_height,im_proj, im_geotrans, im_data\n",
    "    # 写文件，以写成tif为例\n",
    "    def write_img(self, filename, im_proj, geoTransform, im_data):\n",
    "        # gdal数据类型包括\n",
    "        # gdal.GDT_Byte,\n",
    "        # gdal .GDT_UInt16, gdal.GDT_Int16, gdal.GDT_UInt32, gdal.GDT_Int32,\n",
    "        # gdal.GDT_Float32, gdal.GDT_Float64\n",
    "\n",
    "        # 判断栅格数据的数据类型\n",
    "        if 'int8' in im_data.dtype.name:\n",
    "            datatype = gdal.GDT_Byte\n",
    "        elif 'int16' in im_data.dtype.name:\n",
    "            datatype = gdal.GDT_UInt16\n",
    "        else:\n",
    "            datatype = gdal.GDT_Float32\n",
    "\n",
    "        # 判读数组维数\n",
    "        if len(im_data.shape) == 3:\n",
    "            im_height, im_width ,im_bands = im_data.shape\n",
    "        else:\n",
    "            im_bands, (im_height, im_width) = 1, im_data.shape\n",
    "\n",
    "            # 创建文件\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")  # 数据类型必须有，因为要计算需要多大内存空间\n",
    "        dataset = driver.Create(filename, im_width, im_height, im_bands, datatype)\n",
    "\n",
    "        dataset.SetGeoTransform(geoTransform)  # 写入仿射变换参数\n",
    "        dataset.SetProjection(im_proj)  # 写入投影\n",
    "\n",
    "        if im_bands == 1:\n",
    "            dataset.GetRasterBand(1).WriteArray(im_data)  # 写入数组数据\n",
    "        else:\n",
    "            for i in range(im_bands):\n",
    "                dataset.GetRasterBand(i + 1).WriteArray(im_data[i])\n",
    "\n",
    "        del dataset\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    file_name = \"/kaggle/input/test-img-2/water.tif\"\n",
    "    width, height ,proj, geotrans, img = GRID().read_img(file_name)  # 读数据    image_result_all代表最终分割影像\n",
    "    #参数设计\n",
    "    rate_width = width // 512\n",
    "    rate_height = height // 512\n",
    "    input_img = np.zeros((2,(rate_height + 1) * 512, (rate_width + 1) * 512))\n",
    "    input_img[0,0:height,0:width] = img[0]\n",
    "    input_img[1,0:height,0:width] = img[1]\n",
    "    size = 512\n",
    "    k=0\n",
    "    end_water = np.zeros(((rate_height + 1) * 512, (rate_width + 1) * 512))  # 代表最终结果\n",
    "    for i in range(rate_height+1):\n",
    "        for j in range(rate_width+1):\n",
    "                print(k,i,j)\n",
    "\n",
    "                img_vv = input_img[0, i * size:(i + 1) * size, j * size:(j + 1) * size]\n",
    "                img_vh = input_img[1, i * size:(i + 1) * size, j * size:(j + 1) * size]\n",
    "               \n",
    "                img_vv = np.clip(img_vv, -30, 0)\n",
    "                img_vh = np.clip(img_vh, -30, 0)\n",
    "\n",
    "                # 计算水体指数\n",
    "                img_mid = 10 * img_vv * img_vh\n",
    "                img_mid[img_mid <= 0] = 1\n",
    "                img_math = np.log(img_mid)\n",
    "                # print(\"img_math最小值，最大值，平均值分别为：\", np.min(img_math), np.max(img_math), img_math.dtype)\n",
    "\n",
    "                # 将img_math,img_vv,img_vh范围扩大到【0,255】\n",
    "                img_math = ((img_math - np.min(img_math)) / (np.max(img_math) - np.min(img_math)) * 255).astype( np.uint8)\n",
    "                img_vh = ((img_vh - np.min(img_vh)) / (np.max(img_vh) - np.min(img_vh)) * 255).astype(np.uint8)\n",
    "                img_vv = ((img_vv - np.min(img_vv)) / (np.max(img_vv) - np.min(img_vv)) * 255).astype(np.uint8)\n",
    "                \n",
    "                #波段合成\n",
    "                img_math_result = np.stack([img_vh, img_vv, img_math],axis = 2)\n",
    "    \n",
    "                test_image = np.expand_dims(img_math_result, axis=0)\n",
    "                \n",
    "                predict_image = model.predict(test_image)\n",
    "                predict_image = np.squeeze(predict_image)\n",
    "                predict_image = np.where(predict_image > 0.5, 1., 0.)\n",
    "\n",
    "                end_water[i * size:(i + 1) * size, j * size:(j + 1) * size] = predict_image\n",
    "                k = k + 1\n",
    "    GRID().write_img(\"./model_result.tif\",proj,geotrans,end_water)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
